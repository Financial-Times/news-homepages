{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fbc2dc7-9a1f-4a35-88b3-15302517f70c",
   "metadata": {},
   "source": [
    "# Drudge entities analysis\n",
    "\n",
    "By Ben Welsh\n",
    "\n",
    "A draft analysis of the top words in headlines from the Drudge Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa495b6-42b1-4cd5-b373-9bfbb2e1e8ec",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef76ba-b4f8-47b5-8d4f-7ed56dfd2c69",
   "metadata": {},
   "source": [
    "Python tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452aef46-1d4f-45c9-aeea-0c3ea967bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca8053-7e7f-47f7-b7e1-4c53310ae199",
   "metadata": {},
   "source": [
    "Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25447174-9b38-402a-b42b-6d34bc0d6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915d20d-c303-4abe-bbd7-6c3c051532e6",
   "metadata": {},
   "source": [
    "Natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daba313f-4f43-4b67-9756-3e7fc98c02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85479033-c6a5-4ba7-86fd-2c7b271df87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pipenv run python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1ad54a-b507-4787-a132-dd5b9f43609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3ae12-57ce-4fe7-b25c-b018f1abc3cd",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d02dbf3-eb13-4718-9025-5c84d85d918e",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b89533-20dd-4c33-bb7a-7d559a6a2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_df = pd.read_csv(\n",
    "    \"../extracts/csv/us-right-wing-hyperlinks-analysis.csv\",\n",
    "    parse_dates=[\"earliest_date\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58ffc6c-9ab6-44f1-9a9f-99434119f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21389 entries, 0 to 21388\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   handle         21389 non-null  object        \n",
      " 1   text           20138 non-null  object        \n",
      " 2   url            21389 non-null  object        \n",
      " 3   earliest_date  21389 non-null  datetime64[ns]\n",
      " 4   is_story       21389 non-null  bool          \n",
      " 5   domain         21389 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), object(4)\n",
      "memory usage: 856.5+ KB\n"
     ]
    }
   ],
   "source": [
    "link_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e2a348-deb0-4224-b100-df88d9b9488f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-11-02 00:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df.earliest_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47b6a30d-32d4-4089-b3f6-fadc65dee982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-11-08 00:00:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df.earliest_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b352d8cb-4552-4742-8ed6-6253ba091653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>earliest_date</th>\n",
       "      <th>is_story</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DailyCaller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/2022/11/08/cole-hauser-rip-wheeler-death-futu...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DailyCaller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/2022/11/08/donald-trump-jd-vance-ohio-midterm...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DailyCaller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/2022/11/08/florida-prepared-subtropical-storm...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DailyCaller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/2022/11/08/lab-leak-theory-democrats-investig...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DailyCaller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/2022/11/08/mistake-sylvester-stallone-almost-...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        handle text                                                url  \\\n",
       "0  DailyCaller  NaN  /2022/11/08/cole-hauser-rip-wheeler-death-futu...   \n",
       "1  DailyCaller  NaN  /2022/11/08/donald-trump-jd-vance-ohio-midterm...   \n",
       "2  DailyCaller  NaN  /2022/11/08/florida-prepared-subtropical-storm...   \n",
       "3  DailyCaller  NaN  /2022/11/08/lab-leak-theory-democrats-investig...   \n",
       "4  DailyCaller  NaN  /2022/11/08/mistake-sylvester-stallone-almost-...   \n",
       "\n",
       "  earliest_date  is_story domain  \n",
       "0    2022-11-08     False      .  \n",
       "1    2022-11-08     False      .  \n",
       "2    2022-11-08     False      .  \n",
       "3    2022-11-08     False      .  \n",
       "4    2022-11-08     False      .  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440acb4-af3b-46d5-ac48-f10f90603144",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4074e086-bc90-4969-8b19-240495176ef4",
   "metadata": {},
   "source": [
    "Filter down to stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5058f18-7ece-4769-8793-8d6402a88e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_df = link_df[\n",
    "    (link_df.is_story) &\n",
    "    ~(pd.isnull(link_df.text))\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de4607-2b6d-4d74-b7b9-803d023c6921",
   "metadata": {},
   "source": [
    "Cut `...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6270e2a-ee19-4798-861c-3ddbfc64a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_df.text = story_df.text.str.replace(r\"\\.{2,}\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9a12bda-c31b-434a-b818-22b2a66f56be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-11-02    1645\n",
       "2022-11-08    1533\n",
       "2022-11-04    1050\n",
       "2022-11-03     970\n",
       "2022-11-07     730\n",
       "2022-11-06     611\n",
       "2022-11-05     594\n",
       "Name: earliest_date, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_df.earliest_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a373f6df-2a70-4901-89f5-5d80c8581bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_df.url = story_df.url.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ced31d22-4fa1-438a-ab7d-2e03f923b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_df = story_df[story_df.earliest_date == '2022-11-08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6b21c750-d33d-473b-960f-ca7c87f19f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_df.to_csv(\"us-right-wing-election-headlines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481d0d1-d9e3-4da9-9c50-31001644303f",
   "metadata": {},
   "source": [
    "Extract all unique headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f888f159-98ac-4c80-8fbe-28f14180a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_list = sorted(list(today_df.text.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e53f1-ff08-4783-8a33-a8c25a5a2567",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a114ec16-48dc-4c40-be61-658caec75516",
   "metadata": {},
   "source": [
    "Pull out all of the meaningful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7069caa9-9742-4e88-bd07-17e83808ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(headline: str) -> typing.Dict:\n",
    "    \"\"\"Parse all of the words we want to keep in the headline.\"\"\"\n",
    "    # Read it into our NPL thing\n",
    "    doc = nlp(headline)\n",
    "    \n",
    "    # Parse out all the words\n",
    "    token_list = [token for token in doc]\n",
    "\n",
    "    # Remove stop words\n",
    "    token_list = [t for t in token_list if not t.is_stop]\n",
    "\n",
    "    # Remove punctuation words\n",
    "    token_list = [t for t in token_list if not t.is_punct]\n",
    "\n",
    "    # Remove digits\n",
    "    token_list = [t for t in token_list if not t.is_digit]\n",
    "\n",
    "    # Trim it down to only the stuff we want to keep\n",
    "    dict_list = [dict(\n",
    "        headline=headline,\n",
    "        word=t.text.upper(),\n",
    "        lemma=t.lemma_.upper(),\n",
    "        part_of_speech=t.pos_,\n",
    "    ) for t in token_list]\n",
    "    \n",
    "    # Pass it back\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75e84a08-bd12-4bef-8ffd-3e04ce4b63d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ad8e1023e43b7958e0d0732a1dcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_list = []\n",
    "for headline in track(headline_list):\n",
    "    word_list += get_lemma(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c348ee6c-273d-4141-872d-a19cf1d78243",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5094b4de-af0e-4033-8c37-e2be8feaaf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7054 entries, 0 to 7053\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   headline        7054 non-null   object\n",
      " 1   word            7054 non-null   object\n",
      " 2   lemma           7054 non-null   object\n",
      " 3   part_of_speech  7054 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 220.6+ KB\n"
     ]
    }
   ],
   "source": [
    "word_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa47f380-74d9-492d-bfd7-969036f0ff4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>part_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Car Vending Machine\" Company Carvana's Stock ...</td>\n",
       "      <td>CAR</td>\n",
       "      <td>CAR</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Car Vending Machine\" Company Carvana's Stock ...</td>\n",
       "      <td>VENDING</td>\n",
       "      <td>VEND</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Car Vending Machine\" Company Carvana's Stock ...</td>\n",
       "      <td>MACHINE</td>\n",
       "      <td>MACHINE</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Car Vending Machine\" Company Carvana's Stock ...</td>\n",
       "      <td>COMPANY</td>\n",
       "      <td>COMPANY</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Car Vending Machine\" Company Carvana's Stock ...</td>\n",
       "      <td>CARVANA</td>\n",
       "      <td>CARVANA</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline     word    lemma  \\\n",
       "0  \"Car Vending Machine\" Company Carvana's Stock ...      CAR      CAR   \n",
       "1  \"Car Vending Machine\" Company Carvana's Stock ...  VENDING     VEND   \n",
       "2  \"Car Vending Machine\" Company Carvana's Stock ...  MACHINE  MACHINE   \n",
       "3  \"Car Vending Machine\" Company Carvana's Stock ...  COMPANY  COMPANY   \n",
       "4  \"Car Vending Machine\" Company Carvana's Stock ...  CARVANA  CARVANA   \n",
       "\n",
       "  part_of_speech  \n",
       "0           NOUN  \n",
       "1           VERB  \n",
       "2           NOUN  \n",
       "3          PROPN  \n",
       "4          PROPN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce09ce0-3f02-4c76-9a77-0faa2f97de16",
   "metadata": {},
   "source": [
    "Remove our extra stop words, as well as all symbols and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54c1e77e-9d43-428c-ab14-00cb822f5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = [\n",
    "    \"COMMENTS\",\n",
    "    \"COMMENT\",\n",
    "    # \"NEW\",\n",
    "    # \"MAN\",\n",
    "    # \"WOMAN\",\n",
    "    # \"YEAR\",\n",
    "    # \"DAY\",\n",
    "    # \"MILLION\",\n",
    "    # \"HIGH\",\n",
    "    # \"BIG\",\n",
    "    # \"RECORD\",\n",
    "    # \"HOME\",\n",
    "    # \"WORLD\",\n",
    "    # \"STATE\",\n",
    "    # \"TIME\",\n",
    "    # \"CASE\",\n",
    "    # \"LIFE\",\n",
    "    # \"AMERICAN\",\n",
    "    # \"INSIDE\",\n",
    "    # \"EX\",\n",
    "    # \"MAR\",\n",
    "    # \"HIT\",\n",
    "    # \"LAGO\",\n",
    "    # \"RISE\",\n",
    "    # \"AMID\",\n",
    "    # \"WARNS\",\n",
    "    # \"RATE\",\n",
    "    # \"SHOW\",\n",
    "    # \"ATTACK\",\n",
    "    # \"RISE\",\n",
    "    # \"DEAD\",\n",
    "    # \"SET\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab36e66a-cb25-4909-8b28-d284261d9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified_df = word_df[\n",
    "    (~word_df.part_of_speech.isin([\"SYM\", \"VERB\"])) &\n",
    "    (~word_df.lemma.isin(stop_list))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd42ad-4e6e-419f-a937-3362418e7d49",
   "metadata": {},
   "source": [
    "Calculate the 25 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45c5584e-2d02-4b14-80b7-7184ddcdc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = (\n",
    "    qualified_df.groupby(\"lemma\")\n",
    "        .size()\n",
    "        .rename(\"n\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"n\", ascending=False)\n",
    "        .head(25)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f604e-90c6-404a-ad40-c7b71811a0c0",
   "metadata": {},
   "source": [
    "Get the top verb used with each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "983d5093-079f-41bc-acb5-54c5800f465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headlines(lemma: str) -> typing.List:\n",
    "    \"\"\"Get all the headlines for the provided word.\"\"\"\n",
    "    return sorted(list(qualified_df[qualified_df.lemma == lemma].headline.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d343b8aa-5616-4ee3-a6e7-da1de1d011c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_verb(lemma: str) -> str:\n",
    "    \"\"\"Get the top verb in the provided lemma's headline set.\"\"\"\n",
    "    # Set our stop words for the verbs\n",
    "    stop_verbs = [\"SAYS\", \"HAS\", \"GETS\", \"GET\", \"LULA\", \"ELON\", \"SAY\", \"HAVE\",]\n",
    "    if lemma == \"COVID\":\n",
    "        stop_verbs += [\"TESTS\"]\n",
    "    if lemma == \"MUSK\":\n",
    "        stop_verbs += [\"SOCIAL\"]\n",
    "\n",
    "    # Pull the headlines\n",
    "    headline_list = get_headlines(lemma)\n",
    "\n",
    "    # Loop through all of the headlines\n",
    "    master_list = []    \n",
    "    for headline in headline_list:\n",
    "        # Parse the headline again with NLP\n",
    "        doc = nlp(headline)\n",
    "        \n",
    "        # Pull out the verbs\n",
    "        verb_list = [t.lemma_.upper() for t in doc if t.pos_ == \"VERB\"]\n",
    "        \n",
    "        # Cut the stop words\n",
    "        verb_list = [v for v in verb_list if v not in stop_verbs]\n",
    "        \n",
    "        # Add it to our master list\n",
    "        master_list += verb_list\n",
    "    \n",
    "    # Count the verbs\n",
    "    verb_counter = Counter(master_list)\n",
    "    \n",
    "    # Pull the most common one\n",
    "    top_verb = verb_counter.most_common(2)\n",
    "    \n",
    "    # Return the result\n",
    "    return top_verb[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f90ea497-375a-4956-b00a-97352d5a2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words['top_verb'] = top_words.lemma.apply(get_top_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e96fbcb2-ec33-4271-a6d8-71ee42cd5bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>n</th>\n",
       "      <th>top_verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>ELECTION</td>\n",
       "      <td>86</td>\n",
       "      <td>KNOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>BIDEN</td>\n",
       "      <td>57</td>\n",
       "      <td>SHUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>MIDTERM</td>\n",
       "      <td>51</td>\n",
       "      <td>VOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>DAY</td>\n",
       "      <td>42</td>\n",
       "      <td>KNOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>36</td>\n",
       "      <td>MAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>DEMOCRATS</td>\n",
       "      <td>31</td>\n",
       "      <td>LOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>VOTE</td>\n",
       "      <td>29</td>\n",
       "      <td>COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>NEW</td>\n",
       "      <td>28</td>\n",
       "      <td>VOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>BALLOT</td>\n",
       "      <td>27</td>\n",
       "      <td>COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>GOP</td>\n",
       "      <td>27</td>\n",
       "      <td>VOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>COUNTY</td>\n",
       "      <td>26</td>\n",
       "      <td>VOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>VOTER</td>\n",
       "      <td>24</td>\n",
       "      <td>MAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>POLL</td>\n",
       "      <td>24</td>\n",
       "      <td>FIND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>23</td>\n",
       "      <td>SEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>AD</td>\n",
       "      <td>23</td>\n",
       "      <td>HIDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>WORLD</td>\n",
       "      <td>20</td>\n",
       "      <td>ENTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>BIG</td>\n",
       "      <td>19</td>\n",
       "      <td>BECOME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>STATE</td>\n",
       "      <td>19</td>\n",
       "      <td>ENTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>19</td>\n",
       "      <td>VOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>CHINA</td>\n",
       "      <td>17</td>\n",
       "      <td>THINK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>YEAR</td>\n",
       "      <td>17</td>\n",
       "      <td>SEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>HOUSE</td>\n",
       "      <td>17</td>\n",
       "      <td>EXPECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>RACE</td>\n",
       "      <td>16</td>\n",
       "      <td>WIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>MUSK</td>\n",
       "      <td>15</td>\n",
       "      <td>VOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>WATCH</td>\n",
       "      <td>15</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lemma   n top_verb\n",
       "806     ELECTION  86     KNOW\n",
       "278        BIDEN  57     SHUT\n",
       "1549     MIDTERM  51     VOTE\n",
       "650          DAY  42     KNOW\n",
       "2428       TRUMP  36     MAKE\n",
       "689    DEMOCRATS  31     LOSE\n",
       "2519        VOTE  29    COUNT\n",
       "1655         NEW  28     VOTE\n",
       "229       BALLOT  27    COUNT\n",
       "1053         GOP  27     VOTE\n",
       "580       COUNTY  26     VOTE\n",
       "2520       VOTER  24     MAKE\n",
       "1823        POLL  24     FIND\n",
       "2445        U.S.  23      SEE\n",
       "86            AD  23     HIDE\n",
       "2596       WORLD  20    ENTER\n",
       "280          BIG  19   BECOME\n",
       "2237       STATE  19    ENTER\n",
       "1986  REPUBLICAN  19     VOTE\n",
       "441        CHINA  17    THINK\n",
       "2607        YEAR  17      SEE\n",
       "1158       HOUSE  17   EXPECT\n",
       "1915        RACE  16      WIN\n",
       "1624        MUSK  15     VOTE\n",
       "2542       WATCH  15     STAY"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "85ba6b5c-9b6a-4569-b99a-4728d570d3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>part_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [headline, word, lemma, part_of_speech]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualified_df[qualified_df.lemma == \"COMMENT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75f83a-c5f0-45fa-9ba0-6c96299186e6",
   "metadata": {},
   "source": [
    "Get the timeseries for our top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdd2d5df-5f0a-40ba-98e7-0193dd2f996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date, max_date = story_df.earliest_date.min(), story_df.earliest_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f1c9883-2414-4ed6-a1ca-d1e89d673f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeseries(lemma: str) -> typing.List:\n",
    "    \"\"\"Pull the day to day timeseries for the provided word.\"\"\"\n",
    "    # Count the top words by day\n",
    "    df = (\n",
    "        qualified_df[qualified_df.lemma == lemma]\n",
    "            .merge(story_df[['earliest_date', 'text']].rename(columns={\"text\": \"headline\"}), on=\"headline\")\n",
    "            .groupby(\"earliest_date\")\n",
    "            .size()\n",
    "            .rename(\"n\")\n",
    "            .reset_index()\n",
    "            .rename(columns={\"earliest_date\": \"date\"})\n",
    "            .set_index(\"date\")\n",
    "    )\n",
    "    \n",
    "    # Fill in days we're missing\n",
    "    date_range = pd.date_range(\n",
    "        min_date,\n",
    "        max_date,\n",
    "        freq=\"D\",\n",
    "    )\n",
    "    date_index = pd.DatetimeIndex(date_range)\n",
    "    backfilled_df = df.reindex(date_index)\n",
    "    backfilled_df.n.fillna(0, inplace=True)\n",
    "    \n",
    "    # Calculate the 7-day rolling average\n",
    "    backfilled_df['7_day_rolling_average'] = backfilled_df.n.rolling(7).mean()\n",
    "\n",
    "    # Convert it to a dict list\n",
    "    dict_list = backfilled_df.reset_index().rename(columns={\"index\": \"date\"}).to_dict(orient=\"records\")\n",
    "    \n",
    "    # Convert our dates to strings\n",
    "    for d in dict_list:\n",
    "        d['date'] = d['date'].strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Pass it out\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afe81288-10e6-4f44-ae18-03c1a47e1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words['timeseries'] = top_words.lemma.apply(get_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0684ee5-7490-4dd7-962f-5cb37aad5063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>n</th>\n",
       "      <th>top_verb</th>\n",
       "      <th>timeseries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>151</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>[{'date': '2022-08-09', 'n': 5.0, '7_day_rolli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>BIDEN</td>\n",
       "      <td>104</td>\n",
       "      <td>WANT</td>\n",
       "      <td>[{'date': '2022-08-09', 'n': 3.0, '7_day_rolli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>ELECTION</td>\n",
       "      <td>100</td>\n",
       "      <td>VOTE</td>\n",
       "      <td>[{'date': '2022-08-09', 'n': 0.0, '7_day_rolli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>WAR</td>\n",
       "      <td>87</td>\n",
       "      <td>GROW</td>\n",
       "      <td>[{'date': '2022-08-09', 'n': 3.0, '7_day_rolli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>PUTIN</td>\n",
       "      <td>74</td>\n",
       "      <td>BLOW</td>\n",
       "      <td>[{'date': '2022-08-09', 'n': 1.0, '7_day_rolli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lemma    n top_verb  \\\n",
       "7449     TRUMP  151     TAKE   \n",
       "750      BIDEN  104     WANT   \n",
       "2307  ELECTION  100     VOTE   \n",
       "7806       WAR   87     GROW   \n",
       "5547     PUTIN   74     BLOW   \n",
       "\n",
       "                                             timeseries  \n",
       "7449  [{'date': '2022-08-09', 'n': 5.0, '7_day_rolli...  \n",
       "750   [{'date': '2022-08-09', 'n': 3.0, '7_day_rolli...  \n",
       "2307  [{'date': '2022-08-09', 'n': 0.0, '7_day_rolli...  \n",
       "7806  [{'date': '2022-08-09', 'n': 3.0, '7_day_rolli...  \n",
       "5547  [{'date': '2022-08-09', 'n': 1.0, '7_day_rolli...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae527b-861c-4ef8-b983-23063762f9ea",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b64756-85a4-4e39-891a-3a4d0b850042",
   "metadata": {},
   "source": [
    "Proof any words we're curious about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b418d1e8-90e7-4eaa-8547-2267a072bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'MUSK TRANSMITTING MESSAGE FOR PUTIN'\",\n",
       " \"ANOTHER PUTIN CRONY DIES AFTER 'FALLING FROM BOAT'\",\n",
       " 'BIDEN WARNS PUTIN AGAINST USING NUCLEAR OR CHEMICAL WEAPONS',\n",
       " 'CAR-BOMB KILLING SOWS UNEASE AMONG PUTIN CHEERLEADERS',\n",
       " \"DAUGHTER OF 'PUTIN'S BRAIN' KILLED IN CAR BOMB\",\n",
       " \"DESPERATE PUTIN'S DOUBLE TROUBLE\",\n",
       " \"DID PUTIN'S FROGMEN BLOW UP EUROPE'S GAS SUPPLIES?\",\n",
       " \"HOW PUTIN PUSHING ARMY BOSSES THROUGH 'MEAT GRINDER' OF DEATH\",\n",
       " 'IN DC, PUTIN NUKE THREATS STIR GROWING ALARM',\n",
       " 'LEAKED SPY DOCS CLAIM PUTIN TAKING SECRET COCKTAIL OF DRUGS',\n",
       " \"LEAKED SPY DOCS SUGGEST PUTIN DOES HAVE PARKINSON'S, CANCER\",\n",
       " \"MEET PUTIN'S INNER CIRCLE OF EVIL\",\n",
       " 'MUSK APPEASEMENT OF PUTIN AND CHINA STOKES FEARS OF NEW TWITTER POLICIES',\n",
       " 'MUSK DENIES HE TALKED TO PUTIN AHEAD OF CONTROVERSIAL TWEET',\n",
       " \"ODESA DEFIANT. IT'S ALSO PUTIN'S ULTIMATE TARGET\",\n",
       " 'POLAND ASKS USA TO HOST NUKES AMID GROWING PUTIN FEARS',\n",
       " \"PUTIN 'HAS GIVEN ORDER TO DEPLOY NUKES,' CLAIMS KREMLIN INSIDER\",\n",
       " \"PUTIN 'PLANS TO BLOW UP MAJOR DAM'; 'HISTORIC DISASTER'\",\n",
       " 'PUTIN ALLIES NOW SLAMMING WAR TO HIS FACE',\n",
       " 'PUTIN ALLIES RIDICULE WAR MACHINE IN PUBLIC',\n",
       " 'PUTIN ANNOUNCES ANNEXATION OF UKRAINIAN REGIONS BIGGEST LAND GRAB SINCE WWII',\n",
       " 'PUTIN BLASTS HEGEMONY, PREDICTS END TO UNIPOLAR WORLD',\n",
       " 'PUTIN BOASTS OF WEAPONS PROWESS; READY TO SHARE WITH ALLIES',\n",
       " 'PUTIN CIRCLE ON HIGH ALERT AFTER GURU DAUGHTER BLOWN UP',\n",
       " \"PUTIN CRONIES THREATEN 'HUNDREDS' OF AMERICAN COFFINS ON LIVE TV\",\n",
       " 'PUTIN DECLARES MARTIAL LAW IN ANNEXED REGIONS',\n",
       " 'PUTIN ECHOING STALIN 1939',\n",
       " 'PUTIN ESCAPES TO SECRET PALACE IN FOREST AMID ANTI-DRAFT PROTESTS',\n",
       " 'PUTIN FACES TOUGHEST CHALLENGE YET AS LEADER',\n",
       " 'PUTIN FIRES MASSIVE MISSILE BARRAGE ACROSS UKRAINIAN CITIES',\n",
       " \"PUTIN HANDS 'TURNING BLACK'\",\n",
       " 'PUTIN HUMILIATION',\n",
       " \"PUTIN INVASION 'UNLIKELY TO SUCCEED' AFTER SIGNIFICANT LOSSES\",\n",
       " 'PUTIN ISOLATED IN BUNKER',\n",
       " 'PUTIN LOSING CONTROL',\n",
       " 'PUTIN NUKE FINALE?',\n",
       " 'PUTIN ORDERS RUSSIA TO RECRUIT MORE TROOPS AS WAR DRAGS',\n",
       " \"PUTIN OVERSEES 'MASSIVE NUKE STRIKE ON WEST' DURING DRILLS\",\n",
       " 'PUTIN PLOTS REVENGE',\n",
       " 'PUTIN PLOTTING TO UNLEASH HELL ON INDEPENDENCE DAY?',\n",
       " 'PUTIN PRIVATE ARMY ACCUSED OF COMMITTING MOST HEINOUS MASSACRE YET',\n",
       " 'PUTIN REPLACEMENT COULD BE MORE DANGEROUS, EXPERT WARNS',\n",
       " \"PUTIN SENDS BOMBERS TO BASE AS FEARS OF RISE: 'IRREGULAR PRESENCE'\",\n",
       " 'PUTIN SET TO ANNEX UKRAINE LANDS, IGNORING CRITICISM',\n",
       " 'PUTIN SET TO WEAPONIZE WINTER',\n",
       " 'PUTIN SHOWN IN TENSE ENCOUNTER WITH CHIEF OF STAFF',\n",
       " \"PUTIN SPOKESMAN'S WIFE ON PLATE-SMASHING RAMPAGE IN GREECE\",\n",
       " 'PUTIN THREAT TO STOP ALL EUROPE ENERGY EXPORTS',\n",
       " 'PUTIN THREATENS WEST WITH NUKES',\n",
       " 'PUTIN TO SNUB GORBACHEV FUNERAL',\n",
       " \"PUTIN WARNS 'CATASTROPHE'\",\n",
       " \"PUTIN WON'T\",\n",
       " \"PUTIN'S ARMY RUNNING SCARED AS MAPS SHOW HUGE UKRAINIAN ADVANCE IN JUST HOURS\",\n",
       " \"PUTIN'S CHIEFS ARE BEING BLOWN UP, POISONED AND SHOT\",\n",
       " \"PUTIN'S FEET TWITCH UNCONTROLLABLY AGAIN\",\n",
       " \"PUTIN'S PRIZED BRIDGE DESTROYED\",\n",
       " \"PUTIN'S TWO BIGGEST WAR HAWKS TURNING ON HIM\",\n",
       " \"PUTIN'S WORST CASE SCENARIO COMING TRUE\",\n",
       " 'PUTIN: WESTERN DOMINATION OVER, CALLS FOR NEW WORLD ORDER',\n",
       " 'PUTIN’S RUMOURED GODDAUGHTER FLEES TO LITHUANIA',\n",
       " \"REPORT: PUTIN TRIED TO DETONATE NUKE BUT PLANS WERE 'SABOTAGED'\",\n",
       " 'STUNNING AUDIO OF INTERCEPTED RUSSIAN SOLDIER CALLS REVEALS PANIC IN RANKS ORDERS TO KILL CIVILIANS, UTTER DISDAIN FOR PUTIN',\n",
       " 'THE MYSTERY MAN VOWING PUTIN FRIENDS WILL GET BLOWN UP SOON',\n",
       " 'THE SH*T-POSTING, TROLLING, DOG-DEPLOYING SOCIAL MEDIA ARMY TAKING ON PUTIN',\n",
       " \"TOP GENERAL FILMED LYING TO PUTIN'S FACE\",\n",
       " 'UAE REACHES OUT TO PUTIN',\n",
       " 'VICTORY OR NUKES? PUTIN BACKS SELF FURTHER INTO CORNER',\n",
       " \"WAR AT PIVOTAL MOMENT AS ZELENSKY'S MILITARY CONTINUES TO COUNTER PUTIN\",\n",
       " \"WEST'S PLAN TO AVOID PANIC IF PUTIN GOES RADIOACTIVE\",\n",
       " 'WHAT COULD HAPPEN IF PUTIN USES NUKES?',\n",
       " 'XI LEAVES CHINA FOR FIRST TIME SINCE COVID TO MEET PUTIN',\n",
       " 'XI WARNS PUTIN NOT TO USE NUKES',\n",
       " 'XI, PUTIN LOOK TO CHALLENGE WORLD ORDER AT SUMMIT',\n",
       " 'XI, PUTIN SET FOR FIRST MEETING SINCE INVASION']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_headlines(\"PUTIN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
